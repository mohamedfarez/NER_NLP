# -*- coding: utf-8 -*-
"""NER_NLP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tGsdAzvS1vYlqmtsJuXEMMoYos9ZJFyF
"""

import pandas as pd
import spacy
from spacy.tokens import DocBin
from spacy.training.example import Example
from spacy.util import minibatch
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split

import pandas as pd

# Try reading only the first few rows to see if the error persists
try:
    data = pd.read_csv('NER_Dataset.csv', nrows=1000)
    print("Successfully read the first 1000 rows. The issue might be in the later part of the file.")
except pd.errors.ParserError as e:
    print(f"Error still occurs even when reading a smaller portion: {e}")

data.head()

data['Word'][3]

data['Tag'][3]

data.shape

# checking for duplicates
duplicates_count=data.duplicated().sum()
duplicates_count

# Parse the data
sentences = data['Word'].tolist()
pos_tags = data['POS'].apply(eval).tolist()
ner_tags = data['Tag'].apply(eval).tolist()

pos_tags[0]

ner_tags[0]

# Function to convert data into spaCy format
def convert_to_spacy_format(sentences, pos_tags, ner_tags):
    training_data = []
    for sentence, pos, ner in zip(sentences, pos_tags, ner_tags):
        entities = []
        start = 0
        for word, tag in zip(sentence.split(), ner):
            end = start + len(word)
            if tag != 'O':
                entities.append((start, end, tag))
            start = end + 1
        training_data.append((sentence, {"entities": entities}))
    return training_data

# Convert data
training_data = convert_to_spacy_format(sentences, pos_tags, ner_tags)

len(training_data)

"""## **Splitting data into train, validation and test datasets**"""

train_data, temp_data = train_test_split(training_data, test_size=0.2, random_state=42)
val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)

# Function to create a DocBin for training
def create_docbin(training_data, nlp):
    doc_bin = DocBin()
    for text, annot in training_data:
        doc = nlp.make_doc(text)
        example = Example.from_dict(doc, annot)
        doc_bin.add(example.reference)
    return doc_bin

# Load a pre-trained English model (small)
nlp = spacy.load('en_core_web_sm')

# Create the NER component
ner = nlp.get_pipe('ner')

# Add labels
for _, annotations in training_data:
    for ent in annotations.get('entities'):
        ner.add_label(ent[2])

# Create DocBin for training and validation data
train_doc_bin = create_docbin(train_data, nlp)
val_doc_bin = create_docbin(val_data, nlp)

train_doc_bin

from collections import Counter

# Function to get label distribution
def get_label_distribution(data):
    labels = []
    for text, annot in data:
        for start, end, label in annot['entities']:
            labels.append(label)
    return Counter(labels)

# Get distribution for each dataset
train_distribution = get_label_distribution(train_data)
val_distribution = get_label_distribution(val_data)
test_distribution = get_label_distribution(test_data)

# Convert distribution data to DataFrame
def distribution_to_df(distribution, dataset_name):
    df = pd.DataFrame(distribution.items(), columns=['Label', 'Count'])
    df['Dataset'] = dataset_name
    return df

# Get distributions
train_df = distribution_to_df(train_distribution, 'Training')
val_df = distribution_to_df(val_distribution, 'Validation')
test_df = distribution_to_df(test_distribution, 'Test')

# Combine all into a single DataFrame
df = pd.concat([train_df, val_df, test_df], ignore_index=True)

import matplotlib.pyplot as plt
# Plot the distribution
plt.figure(figsize=(15, 6))
sns.barplot(x='Label', y='Count', hue='Dataset', data=df)
plt.title('Label Distribution Across Datasets')
plt.xticks(rotation=90)
plt.show()

# Training the model
optimizer = nlp.resume_training()

# Fine-tuning the model
for i in range(20):
    losses = {}
    batches = minibatch(train_data, size=8)
    for batch in batches:
        texts, annotations = zip(*batch)
        examples = [Example.from_dict(nlp.make_doc(text), ann) for text, ann in zip(texts, annotations)]
        nlp.update(examples, drop=0.35, losses=losses)
    print(f"Iteration {i}: Losses {losses}")

# Save  trained model
nlp.to_disk("custom_ner_model")

# Load  trained model
nlp = spacy.load("custom_ner_model")

#Model Evaluation
def evaluate_model(nlp, data):
    results = []
    for text, annot in data:
        doc = nlp(text)
        true_entities = [(start, end, label) for start, end, label in annot['entities']]
        pred_entities = [(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]
        results.append((true_entities, pred_entities, text))  # Ensure the tuple is in this format
    return results

# Evaluate on validation set
val_results = evaluate_model(nlp, val_data)
# Evaluate on test set
test_results = evaluate_model(nlp, test_data)

def flatten_results_by_token(nlp, results):
    true_labels = []
    pred_labels = []

    for result in results:
        true_entities = result[0]  # Extract true_entities
        pred_entities = result[1]  # Extract pred_entities

        true_dict = {(start, end): label for start, end, label in true_entities}
        pred_dict = {(start, end): label for start, end, label in pred_entities}

        # Collect all unique start positions
        all_starts = sorted(set([start for start, end in true_dict.keys()] + [start for start, end in pred_dict.keys()]))

        for start in all_starts:
            # Use token alignment with start position
            true_label = true_dict.get((start, start+1), 'O')
            pred_label = pred_dict.get((start, start+1), 'O')
            true_labels.append(true_label)
            pred_labels.append(pred_label)

    return true_labels, pred_labels

val_true_labels, val_pred_labels = flatten_results_by_token(nlp, val_results)
test_true_labels, test_pred_labels = flatten_results_by_token(nlp, test_results)

from sklearn.metrics import confusion_matrix, precision_recall_curve, average_precision_score,classification_report
# Calculate classification report for validation set
val_report = classification_report(val_true_labels, val_pred_labels, zero_division=1)
print("Validation Classification Report:")
print(val_report)

# Calculate classification report for test set
test_report = classification_report(test_true_labels, test_pred_labels, zero_division=1)
print("Test Classification Report:")
print(test_report)

import matplotlib.pyplot as plt
# Confusion Matrix for Validation Set
val_cm = confusion_matrix(val_true_labels, val_pred_labels)
plt.figure(figsize=(10, 7))
sns.heatmap(val_cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix - Validation Set')
plt.show()

# Confusion Matrix for Test Set
test_cm = confusion_matrix(test_true_labels, test_pred_labels)
plt.figure(figsize=(10, 7))
sns.heatmap(test_cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix - Test Set')
plt.show()

# Precision-Recall Curve (Example for a specific label, adapt as needed)
from sklearn.preprocessing import label_binarize

# Assuming 'ORG' is a label you want to plot
val_true_binary = label_binarize(val_true_labels, classes=['O', 'ORG'])
val_pred_scores = label_binarize(val_pred_labels, classes=['O', 'ORG'])

# Access the correct column (index 0 for the first and only column)
precision, recall, _ = precision_recall_curve(val_true_binary[:, 0], val_pred_scores[:, 0])
average_precision = average_precision_score(val_true_binary[:, 0], val_pred_scores[:, 0])

plt.figure()
plt.step(recall, precision, where='post')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve for "ORG" Label (Validation Set)')
plt.show()

#  labels from predictions
pred_labels = [ent.label_ for doc in nlp.pipe([text for text, _ in val_data]) for ent in doc.ents]

# distribution
pred_distribution = Counter(pred_labels)
pred_df = pd.DataFrame(pred_distribution.items(), columns=['Label', 'Count'])

# Plot distribution
plt.figure(figsize=(14, 8))
sns.barplot(x='Label', y='Count', data=pred_df, palette='viridis')
plt.title('Predicted Label Distribution')
plt.xlabel('Labels')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.show()

from spacy import displacy

def visualize_entities_with_displacy(text, true_entities, pred_entities):
    doc = nlp(text)

    # Set up colors
    colors = {
    "B-eve": "#ff9999",
    "B-geo": "#66b3ff",
    "B-org": "#99ff99",
    "B-tim": "#ffcc99",
    "I-art": "#c2c2f0",
    "I-eve": "#ffb3e6",
    "I-geo": "#c2f0c2",
    "I-org": "#c4e17f",
    "I-per": "#ffb3b3",
    "I-tim": "#b3b3b3"
    }

    # Create annotations for true entities
    true_annotations = {"entities": true_entities}

    # Render true entities
    print("True Entities:")
    displacy.render(doc, style="ent", options={"colors": colors})

    # Create a new Doc object for predictions
    doc_pred = nlp(text)
    doc_pred.ents = [doc_pred.char_span(start, end, label) for start, end, label in pred_entities]

    # Render predicted entities
    print("Predicted Entities:")
    displacy.render(doc_pred, style="ent", options={"colors": colors})

# Example usage
for text, annot in val_data[3:5]:
    true_entities = annot['entities']
    pred_entities = [(ent.start_char, ent.end_char, ent.label_) for ent in nlp(text).ents]
    if true_entities or pred_entities:  # Plot only if there are entities to show
        visualize_entities_with_displacy(text, true_entities, pred_entities)
    else:
        print("No entities found in this example.")

